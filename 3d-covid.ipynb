{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import miscnn\n",
    "from miscnn.data_loading.interfaces.nifti_io import NIFTI_interface\n",
    "from miscnn.data_loading.data_io import Data_IO\n",
    "from miscnn.processing.subfunctions.normalization import Normalization\n",
    "from miscnn.processing.subfunctions.clipping import Clipping\n",
    "from miscnn.processing.subfunctions.resampling import Resampling\n",
    "from miscnn.processing.data_augmentation import Data_Augmentation\n",
    "from miscnn.processing.preprocessor import Preprocessor\n",
    "from miscnn.neural_network.model import Neural_Network\n",
    "from miscnn.neural_network.architecture.unet.dense import Architecture\n",
    "from miscnn.neural_network.metrics import tversky_crossentropy, dice_soft, dice_crossentropy, tversky_loss\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, TensorBoard, EarlyStopping, CSVLogger\n",
    "from miscnn.evaluation.cross_validation import cross_validation\n",
    "\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import zipfile\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Links to the data set\n",
    "url_vol = \"https://zenodo.org/record/3757476/files/COVID-19-CT-Seg_20cases.zip?download=1\"\n",
    "url_seg = \"https://zenodo.org/record/3757476/files/Lung_and_Infection_Mask.zip?download=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_from_url(url, dst):\n",
    "    \"\"\"\n",
    "    @param: url to download file\n",
    "    @param: dst place to put the file\n",
    "    \"\"\"\n",
    "    file_size = int(requests.head(url).headers[\"Content-Length\"])\n",
    "    if os.path.exists(dst):\n",
    "        first_byte = os.path.getsize(dst)\n",
    "    else:\n",
    "        first_byte = 0\n",
    "    if first_byte >= file_size:\n",
    "        print(\"WARNING: Skipping download due to files are already there.\")\n",
    "        return file_size\n",
    "    header = {\"Range\": \"bytes=%s-%s\" % (first_byte, file_size)}\n",
    "    pbar = tqdm(\n",
    "        total=file_size, initial=first_byte,\n",
    "        unit='B', unit_scale=True, desc=url.split('/')[-1])\n",
    "    req = requests.get(url, headers=header, stream=True)\n",
    "    with(open(dst, 'ab')) as f:\n",
    "        for chunk in req.iter_content(chunk_size=1024):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "                pbar.update(1024)\n",
    "    pbar.close()\n",
    "    return file_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data structure\n",
    "if not os.path.exists(path_data) : os.makedirs(path_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download CT volumes and save them into the data directory\n",
    "path_vol_zip = os.path.join(path_data, \"volumes.zip\")\n",
    "print(\"INFO:\", \"Downloading Volumes\")\n",
    "download_from_url(url_vol, path_vol_zip)\n",
    "# Download segmentations and save them into the data directory\n",
    "path_seg_zip = os.path.join(path_data, \"segmentations.zip\")\n",
    "print(\"INFO:\", \"Downloading Segmentations\")\n",
    "download_from_url(url_seg, path_seg_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sample list from the ZIP file\n",
    "print(\"INFO:\", \"Obtain sample list from the volumes ZIP file\")\n",
    "with zipfile.ZipFile(path_vol_zip, \"r\") as zip_vol:\n",
    "    sample_list = zip_vol.namelist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the sample list and extract each sample from the ZIP files\n",
    "print(\"INFO:\", \"Extracting data from ZIP files\")\n",
    "for sample in tqdm(sample_list):\n",
    "    # Skip if file does not end with nii.gz\n",
    "    if not sample.endswith(\".nii.gz\") : continue\n",
    "    # Create sample directory\n",
    "    path_sample = os.path.join(path_data, sample[:-len(\".nii.gz\")])\n",
    "    if not os.path.exists(path_sample) : os.makedirs(path_sample)\n",
    "    # Extract volume and store file into the sample directory\n",
    "    with zipfile.ZipFile(path_vol_zip, \"r\") as zip_vol:\n",
    "        zip_vol.extract(sample, path_sample)\n",
    "    os.rename(os.path.join(path_sample, sample),\n",
    "              os.path.join(path_sample, \"imaging.nii.gz\"))\n",
    "    # Extract segmentation and store file into the sample directory\n",
    "    with zipfile.ZipFile(path_seg_zip, \"r\") as zip_seg:\n",
    "        zip_seg.extract(sample, path_sample)\n",
    "    os.rename(os.path.join(path_sample, sample),\n",
    "              os.path.join(path_sample, \"segmentation.nii.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We are using 4 classes due to [background, lung_left, lung_right, covid-19]\n",
    "interface = NIFTI_interface(channels=1, classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_io = miscnn.Data_IO(interface, path_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and configure the Data Augmentation class\n",
    "data_aug = miscnn.Data_Augmentation(cycles=1, scaling=True, rotations=True,\n",
    "                                    elastic_deform=True, mirror=True,\n",
    "                                    brightness=True, contrast=True,\n",
    "                                    gamma=True, gaussian_noise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a clipping Subfunction to the lung window of CTs (-1250 and 250)\n",
    "sf_clipping = Clipping(min=-1250, max=250)\n",
    "# Create a pixel value normalization Subfunction to scale between 0-255\n",
    "sf_normalize = Normalization(mode=\"grayscale\")\n",
    "# Create a resampling Subfunction to voxel spacing 1.58 x 1.58 x 2.70\n",
    "sf_resample = Resampling((1.58, 1.58, 2.70))\n",
    "# Create a pixel value normalization Subfunction for z-score scaling\n",
    "sf_zscore = Normalization(mode=\"z-score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble Subfunction classes into a list\n",
    "sf = [sf_clipping, sf_normalize, sf_resample, sf_zscore]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and configure the Preprocessor class\n",
    "pp = Preprocessor(data_io, data_aug=data_aug, batch_size=2, subfunctions=sf,\n",
    "                  prepare_subfunctions=True, prepare_batches=False,\n",
    "                  analysis=\"patchwise-crop\", patch_shape=(160, 160, 80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the patch overlap for predictions\n",
    "pp.patchwise_overlap = (80, 80, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Architecture\n",
    "unet_dense = Architecture(activation=\"softmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Neural Network model\n",
    "model = Neural_Network(preprocessor=pp, architecture=unet_dense,\n",
    "                       loss=tversky_crossentropy,\n",
    "                       metrics=[tversky_loss, dice_soft, dice_crossentropy],\n",
    "                       batch_queue_size=3, workers=3, learninig_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_list = data_io.get_indiceslist()\n",
    "sample_list.sort()\n",
    "sample_list = sample_list[:-2]\n",
    "sample_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_lr = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=20, verbose=1, mode='min', min_delta=0.0001, \n",
    "                          cooldown=1, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cross-validation function\n",
    "cross_validation(sample_list, model, k_fold=5, epochs=5, iterations=50,\n",
    "                 evaluation_path=\"evaluation\", draw_figures=True, callbacks=[cb_lr], save_models=False, return_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename = \"evaluation/fold_0/validation.dice_soft.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename = \"evaluation/fold_0/validation.loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename = \"evaluation/fold_0/validation.dice_crossentropy.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
